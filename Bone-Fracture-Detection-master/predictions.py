import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing import image
import os
import sqlite3
import hashlib

# load the models when import "predictions.py"
model_elbow_frac = tf.keras.models.load_model("weights/ResNet50_Elbow_frac.h5")
model_hand_frac = tf.keras.models.load_model("weights/ResNet50_Hand_frac.h5")
model_shoulder_frac = tf.keras.models.load_model("weights/ResNet50_Shoulder_frac.h5")
model_parts = tf.keras.models.load_model("weights/ResNet50_BodyParts.h5")

# categories for each result by index

#   0-Elbow     1-Hand      2-Shoulder
categories_parts = ["Elbow", "Hand", "Shoulder"]

#   0-fractured     1-normal
categories_fracture = ['fractured', 'normal']

# Lightweight SQLite cache (by image file name) to persist and reuse prediction results
DB_PATH = os.path.join(os.path.dirname(__file__), 'image_predictions.db')

def _init_db():
    conn = sqlite3.connect(DB_PATH)
    try:
        conn.execute(
            """
            CREATE TABLE IF NOT EXISTS image_predictions (
                image_name TEXT PRIMARY KEY,
                part_result TEXT,
                fracture_result TEXT
            )
            """
        )
        # Ensure image_hash column exists (for robust identification)
        try:
            cur = conn.execute("PRAGMA table_info(image_predictions)")
            cols = [row[1] for row in cur.fetchall()]
            if 'image_hash' not in cols:
                conn.execute("ALTER TABLE image_predictions ADD COLUMN image_hash TEXT")
                # Optionally create an index for faster lookup
                conn.execute("CREATE INDEX IF NOT EXISTS idx_image_hash ON image_predictions(image_hash)")
            # Also ensure we have an index on image_name
            conn.execute("CREATE INDEX IF NOT EXISTS idx_image_name ON image_predictions(image_name)")
        except Exception:
            # SQLite older versions or race conditions: ignore if ALTER TABLE not needed
            pass
    finally:
        conn.close()

_init_db()

def _get_cached(image_hash=None, image_name=None):
    conn = sqlite3.connect(DB_PATH)
    try:
        conn.row_factory = sqlite3.Row
        # Prefer hash lookup when available
        if image_hash:
            cur = conn.execute(
                "SELECT image_name, image_hash, part_result, fracture_result FROM image_predictions WHERE image_hash = ?",
                (image_hash,)
            )
            row = cur.fetchone()
            if row:
                return {
                    'image_name': row['image_name'],
                    'image_hash': row['image_hash'],
                    'part_result': row['part_result'],
                    'fracture_result': row['fracture_result']
                }
        # Fallback to name lookup
        if image_name:
            cur = conn.execute(
                "SELECT image_name, image_hash, part_result, fracture_result FROM image_predictions WHERE image_name = ?",
                (image_name,)
            )
            row = cur.fetchone()
            if row:
                return {
                    'image_name': row['image_name'],
                    'image_hash': row['image_hash'],
                    'part_result': row['part_result'],
                    'fracture_result': row['fracture_result']
                }
        return None
    finally:
        conn.close()

def _save_cached(image_name, image_hash, part_result=None, fracture_result=None):
    conn = sqlite3.connect(DB_PATH)
    try:
        # Upsert by hash first, then by name
        row = None
        if image_hash:
            row = conn.execute(
                "SELECT image_name FROM image_predictions WHERE image_hash = ?",
                (image_hash,)
            ).fetchone()
        if not row and image_name:
            row = conn.execute(
                "SELECT image_name FROM image_predictions WHERE image_name = ?",
                (image_name,)
            ).fetchone()
        if row:
            # Update existing record, set both identifiers
            if part_result is not None:
                conn.execute(
                    "UPDATE image_predictions SET part_result = ?, image_name = ?, image_hash = ? WHERE image_name = ?",
                    (part_result, image_name, image_hash, row[0])
                )
            if fracture_result is not None:
                conn.execute(
                    "UPDATE image_predictions SET fracture_result = ?, image_name = ?, image_hash = ? WHERE image_name = ?",
                    (fracture_result, image_name, image_hash, row[0])
                )
        else:
            conn.execute(
                "INSERT INTO image_predictions (image_name, image_hash, part_result, fracture_result) VALUES (?, ?, ?, ?)",
                (image_name, image_hash, part_result, fracture_result)
            )
        conn.commit()
    finally:
        conn.close()

# get image and model name, the default model is "Parts"
# Parts - bone type predict model of 3 classes
# otherwise - fracture predict for each part
def predict(img, model="Parts"):
    size = 224
    # Identifier: SHA256 of file bytes (primary), and basename (fallback)
    image_name = os.path.basename(img) if isinstance(img, str) else str(img)
    try:
        with open(img, 'rb') as f:
            image_hash = hashlib.sha256(f.read()).hexdigest()
    except Exception:
        image_hash = None
    cached = _get_cached(image_hash=image_hash, image_name=image_name)

    if model == 'Parts':
        if cached and cached.get('part_result'):
            return cached['part_result']
        chosen_model = model_parts
    else:
        if cached and cached.get('fracture_result'):
            return cached['fracture_result']
        if model == 'Elbow':
            chosen_model = model_elbow_frac
        elif model == 'Hand':
            chosen_model = model_hand_frac
        elif model == 'Shoulder':
            chosen_model = model_shoulder_frac
        else:
            chosen_model = model_parts

    # load image with 224px224p (the training model image size, rgb)
    temp_img = image.load_img(img, target_size=(size, size))
    x = image.img_to_array(temp_img)
    x = np.expand_dims(x, axis=0)
    images = np.vstack([x])
    prediction = np.argmax(chosen_model.predict(images), axis=1)

    # chose the category and get the string prediction
    if model == 'Parts':
        prediction_str = categories_parts[prediction.item()]
        _save_cached(image_name=image_name, image_hash=image_hash, part_result=prediction_str)
    else:
        prediction_str = categories_fracture[prediction.item()]
        _save_cached(image_name=image_name, image_hash=image_hash, fracture_result=prediction_str)

    return prediction_str
